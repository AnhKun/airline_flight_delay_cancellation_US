{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1690f805-bbd5-41b2-bef1-37cc6a585e0f",
   "metadata": {},
   "source": [
    "# I. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49bc8971-71d8-4115-b39f-e09c92001e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.types import IntegerType\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea4581f-2039-4a3b-a683-ad6c544dff15",
   "metadata": {},
   "source": [
    "# II. Connect to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a891d67-182f-461e-b72d-c1f4f1326def",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    ".builder \\\n",
    ".appName(\"Wrangling covid19 data\") \\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d93ccaf5-4084-4e2f-b02f-2d0667557c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/jantojun2020.csv'\n",
    "data = spark.read.csv(path, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6553c3b-fbd7-4436-9626-439b44338da3",
   "metadata": {},
   "source": [
    "# III. Assess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f4fdb0e-afdf-48c1-9693-1a9109f0625b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2745847"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0840e009-7ac9-4249-a066-312aa248ff91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['YEAR',\n",
       " 'QUARTER',\n",
       " 'MONTH',\n",
       " 'DAY_OF_MONTH',\n",
       " 'DAY_OF_WEEK',\n",
       " 'FL_DATE',\n",
       " 'MKT_UNIQUE_CARRIER',\n",
       " 'MKT_CARRIER_FL_NUM',\n",
       " 'TAIL_NUM',\n",
       " 'ORIGIN',\n",
       " 'ORIGIN_CITY_NAME',\n",
       " 'ORIGIN_STATE_ABR',\n",
       " 'ORIGIN_STATE_NM',\n",
       " 'DEST',\n",
       " 'DEST_CITY_NAME',\n",
       " 'DEST_STATE_ABR',\n",
       " 'DEST_STATE_NM',\n",
       " 'CRS_DEP_TIME',\n",
       " 'DEP_TIME',\n",
       " 'DEP_DELAY',\n",
       " 'DEP_DELAY_NEW',\n",
       " 'DEP_DEL15',\n",
       " 'DEP_DELAY_GROUP',\n",
       " 'DEP_TIME_BLK',\n",
       " 'TAXI_OUT',\n",
       " 'WHEELS_OFF',\n",
       " 'WHEELS_ON',\n",
       " 'TAXI_IN',\n",
       " 'CRS_ARR_TIME',\n",
       " 'ARR_TIME',\n",
       " 'ARR_DELAY',\n",
       " 'ARR_DELAY_NEW',\n",
       " 'ARR_DEL15',\n",
       " 'ARR_DELAY_GROUP',\n",
       " 'ARR_TIME_BLK',\n",
       " 'CANCELLED',\n",
       " 'CANCELLATION_CODE',\n",
       " 'CRS_ELAPSED_TIME',\n",
       " 'ACTUAL_ELAPSED_TIME',\n",
       " 'AIR_TIME',\n",
       " 'DISTANCE',\n",
       " 'DISTANCE_GROUP',\n",
       " 'CARRIER_DELAY',\n",
       " 'WEATHER_DELAY',\n",
       " 'NAS_DELAY',\n",
       " 'SECURITY_DELAY',\n",
       " 'LATE_AIRCRAFT_DELAY']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7427faba-662c-4d35-9b8f-239cc2bc3eab",
   "metadata": {},
   "source": [
    "# IV. Wrangling data\n",
    "## 1. Split data to dim tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814a4dfc-c11c-4047-a44f-ba7729d0b85b",
   "metadata": {},
   "source": [
    "### 1.1 Create port_loc dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fc99101-fed5-4966-8b52-594eaef4a449",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_port_loc_df(path):\n",
    "    df = spark.read.csv(path, header=True)\n",
    "    for column in df.columns:\n",
    "        df = df.withColumnRenamed(column, column.lower())\n",
    "    port_loc_df = df.select('origin', 'origin_city_name', 'origin_state_abr').dropDuplicates()\n",
    "    port_loc_df = port_loc_df.withColumn('origin_city_name', split(port_loc_df['origin_city_name'], ',').getItem(0))\n",
    "    port_loc_df.toPandas().to_csv('data/port_loc.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9413e179-6b69-4e1b-83c8-f9d4bfd6c731",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_port_loc_df(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa963587-d9a8-4466-bffc-9d9eee69e8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------------+----------------+\n",
      "|origin|origin_city_name|origin_state_abr|\n",
      "+------+----------------+----------------+\n",
      "|   SAF|        Santa Fe|              NM|\n",
      "|   MSP|     Minneapolis|              MN|\n",
      "|   TUL|           Tulsa|              OK|\n",
      "|   DBQ|         Dubuque|              IA|\n",
      "|   LFT|       Lafayette|              LA|\n",
      "|   ROW|         Roswell|              NM|\n",
      "|   PIT|      Pittsburgh|              PA|\n",
      "|   SLN|          Salina|              KS|\n",
      "|   EAU|      Eau Claire|              WI|\n",
      "|   DCA|      Washington|              VA|\n",
      "+------+----------------+----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "port_loc_df = spark.read.csv('data/port_loc.csv', header=True)\n",
    "port_loc_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9013921-9e45-4a11-b143-5c25a20b16ac",
   "metadata": {},
   "source": [
    "### 1.2 Create states dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4bce0066-5986-4bf6-9424-f19b5be48e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_states_df(path):\n",
    "    df = spark.read.csv(path, header=True)\n",
    "    for column in df.columns:\n",
    "        df = df.withColumnRenamed(column, column.lower())\n",
    "    state_df = df.select('origin_state_abr', 'origin_state_nm').dropDuplicates()\n",
    "    state_df.toPandas().to_csv('data/states.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "324f0393-bebf-4380-893f-74c4313392e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_states_df(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31f1832b-f3d9-4b3d-b95d-8f435a095e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------------+\n",
      "|origin_state_abr|    origin_state_nm|\n",
      "+----------------+-------------------+\n",
      "|              VI|U.S. Virgin Islands|\n",
      "|              MT|            Montana|\n",
      "|              NC|     North Carolina|\n",
      "|              MD|           Maryland|\n",
      "|              CO|           Colorado|\n",
      "|              CT|        Connecticut|\n",
      "|              IL|           Illinois|\n",
      "|              WY|            Wyoming|\n",
      "|              NJ|         New Jersey|\n",
      "|              LA|          Louisiana|\n",
      "+----------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "states_df = spark.read.csv('data/states.csv', header=True)\n",
    "states_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d14b200-d22d-4b90-b9c4-3ab1b0bab049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0ee526-a724-4011-bd49-00fb1ba45eae",
   "metadata": {},
   "source": [
    "### 1.3 Create airline dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f53c08e2-6ee4-4627-b02e-0b10f7d35658",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_airline_df(path1,path2):\n",
    "        \"\"\"\n",
    "        Function: Generate and create airlines table code\n",
    "        param:\n",
    "            - path1: txt file\n",
    "            - path2: dataset file\n",
    "        output: airline.csv file stored in data folder\n",
    "        \"\"\"\n",
    "        df = spark.read.csv(path2, header=True)\n",
    "        df2 = df.select(\"MKT_UNIQUE_CARRIER\",\"MKT_CARRIER_FL_NUM\",\"ORIGIN\",\"DEST\",\"TAIL_NUM\").dropDuplicates()\n",
    "        with open(path1) as f:\n",
    "            content = f.readlines()\n",
    "            content = [x.strip() for x in content]\n",
    "            airline = content[10:20]\n",
    "            splitted_airline = [c.split(\":\") for c in airline]\n",
    "            c_airline = [x[0].replace(\"'\",\"\").strip() for x in splitted_airline]\n",
    "            airline_name = [x[1].replace(\"'\",\"\").strip() for x in splitted_airline]\n",
    "            airline_df = spark.createDataFrame(zip(c_airline, airline_name), schema=['c_airline', 'airline_name'])\n",
    "            airline_df = airline_df.join(df2,airline_df.c_airline == df2.MKT_UNIQUE_CARRIER,\"inner\")\\\n",
    "                        .drop(\"MKT_UNIQUE_CARRIER\",\"ORIGIN\",\"DEST\")\n",
    "            return airline_df.toPandas().to_csv(\"data/airline.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "15d78d1f-6a64-4e28-af6a-066537676f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_txt = 'data/ColumnDescriptions.txt'\n",
    "path_csv = 'data/jantojun2020.csv'\n",
    "create_airline_df(path1, path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e751abb6-7294-426a-9f2a-b72eda256a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------------+------------------+--------+\n",
      "|c_airline|   airline_name|MKT_CARRIER_FL_NUM|TAIL_NUM|\n",
      "+---------+---------------+------------------+--------+\n",
      "|       NK|Spirit Airlines|              1009|  N624NK|\n",
      "|       NK|Spirit Airlines|               103|  N654NK|\n",
      "|       NK|Spirit Airlines|              1069|  N913NK|\n",
      "|       NK|Spirit Airlines|               109|  N507NK|\n",
      "|       NK|Spirit Airlines|              1247|  N648NK|\n",
      "|       NK|Spirit Airlines|              1360|  N629NK|\n",
      "|       NK|Spirit Airlines|              1400|  N602NK|\n",
      "|       NK|Spirit Airlines|              1440|  N915NK|\n",
      "|       NK|Spirit Airlines|              1520|  N672NK|\n",
      "|       NK|Spirit Airlines|              1782|  N627NK|\n",
      "+---------+---------------+------------------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "airline_df = spark.read.csv('data/airline.csv', header=True)\n",
    "airline_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1276e3-6f68-4d25-a085-cb5bb841c457",
   "metadata": {},
   "source": [
    "### 1.4 Create distance_group dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50842d99-a77c-4ce2-8fc3-6b1d12a75569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------+\n",
      "|distance|distance_group|\n",
      "+--------+--------------+\n",
      "|     363|             2|\n",
      "|     363|             2|\n",
      "|     333|             2|\n",
      "|     333|             2|\n",
      "|     333|             2|\n",
      "|     333|             2|\n",
      "|     333|             2|\n",
      "|     390|             2|\n",
      "|     390|             2|\n",
      "|     390|             2|\n",
      "+--------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select('distance', 'distance_group').show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b93ce6c-3689-4eb7-aa1c-9dfd96115f71",
   "metadata": {},
   "source": [
    "By observing the table above, we can clearly figure out there are some wrong values in this dataframe: it should be 1 for those distances (Based on the explanation in ColumnDescriptions.txt). Therefore, we will fix it first.\n",
    "##### Fix the wrong distance_group values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b228679-71f5-4cf3-ab5f-3048330b1b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------+\n",
      "|distance|distance_group|\n",
      "+--------+--------------+\n",
      "|     363|             1|\n",
      "|     363|             1|\n",
      "|     333|             1|\n",
      "|     333|             1|\n",
      "|     333|             1|\n",
      "|     333|             1|\n",
      "|     333|             1|\n",
      "|     390|             1|\n",
      "|     390|             1|\n",
      "|     390|             1|\n",
      "+--------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use floor() to get the integer division\n",
    "data = data.withColumn('distance_group', floor(data['distance'].cast('int')/250))\n",
    "# test\n",
    "data.select('distance', 'distance_group').show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d08738-2c19-4b67-921d-10a70022d626",
   "metadata": {},
   "source": [
    "##### Create the wanted dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7eb93f0b-b395-4afb-b00a-3a2f92ee7350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|    distance_group|\n",
      "+-------+------------------+\n",
      "|  count|           2745847|\n",
      "|   mean|  2.50195659117205|\n",
      "| stddev|2.2411625220911175|\n",
      "|    min|                 0|\n",
      "|    max|                20|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select('distance_group').describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250606d9-e346-4a50-8105-02f0a4c79861",
   "metadata": {},
   "source": [
    "Because the min and the max values of the distance_group are 0 and 20, respectively,  we choose the range from 0 to 22 for this distance_group data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1609a73-aa22-4252-82b6-601b1316b2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_distance_group():\n",
    "    data = []\n",
    "    for i in range(23):\n",
    "        data.append([i, \"{} <= distance < {}\".format(i * 250, (i + 1) * 250)])\n",
    "        \n",
    "    df = pd.DataFrame(data=data, columns=['distance_group', 'distance_range(miles)'])\n",
    "    df.to_csv('data/distance_group.csv', index=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "655ec447-1ffa-440b-afb0-3b4983055269",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_distance_group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b8e894e-4e43-428b-b6c8-e15e0d3e8b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------------------+\n",
      "|distance_group|distance_range(miles)  |\n",
      "+--------------+-----------------------+\n",
      "|0             |0 <= distance < 250    |\n",
      "|1             |250 <= distance < 500  |\n",
      "|2             |500 <= distance < 750  |\n",
      "|3             |750 <= distance < 1000 |\n",
      "|4             |1000 <= distance < 1250|\n",
      "|5             |1250 <= distance < 1500|\n",
      "|6             |1500 <= distance < 1750|\n",
      "|7             |1750 <= distance < 2000|\n",
      "|8             |2000 <= distance < 2250|\n",
      "|9             |2250 <= distance < 2500|\n",
      "+--------------+-----------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "distance_group_df = spark.read.csv('data/distance_group.csv', header=True)\n",
    "distance_group_df.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4daabd54-93a8-482a-abd4-bd87d8cd188e",
   "metadata": {},
   "source": [
    "### 1.5 Create cancelation dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7acfbe9c-8908-45ff-9257-de2114c3c73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cancelation_df(path):\n",
    "        \"\"\"\n",
    "        Function: Generate and create Cancelation_code table:\n",
    "        param: Path of datafile\n",
    "        input: .txt file\n",
    "        output: cancel.csv file stored in data folder\n",
    "        \"\"\"\n",
    "        import re\n",
    "        with open(path) as f:\n",
    "            content = f.readlines()\n",
    "            content = [x.strip() for x in content]\n",
    "            cancel = [re.search('\\(([^)]+)', content[49]).group(1)][0].split(\",\")\n",
    "            splitted_cancel = [c.split(\":\") for c in cancel]\n",
    "            c_cancel = [x[0].replace(\"'\",\"\").strip() for x in splitted_cancel]\n",
    "            cancel_des= [x[1].replace(\"'\",\"\").strip() for x in splitted_cancel]\n",
    "            cancel_df = pd.DataFrame({\"c_cancel\" : c_cancel, \"cancel_des\": cancel_des})\n",
    "            return cancel_df.to_csv(\"data/airline.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "755560d0-9f9a-43be-8fae-3e6762368410",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_cancelation_df(path_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fd1dc741-2195-4926-b875-68c3da6fb168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------------+\n",
      "|c_cancel|cancel_des              |\n",
      "+--------+------------------------+\n",
      "|A       |Carrier                 |\n",
      "|B       |Weather                 |\n",
      "|C       |National Aviation System|\n",
      "|D       |Security                |\n",
      "+--------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "cancel_df = spark.read.csv('data/airline.csv', header=True)\n",
    "cancel_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6c0c2c-f033-48e0-8886-7929f26ad3f5",
   "metadata": {},
   "source": [
    "### 1.6 Create delay_group dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "01df0aa1-ec39-4cfd-a6b5-aa10d419f5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_delay_group():\n",
    "        \"\"\"\n",
    "        function\n",
    "        \"\"\"\n",
    "        data = []\n",
    "        for i in range(-1,188):\n",
    "            if i == -1:\n",
    "                data.append([-1,\"Early\"])\n",
    "            elif i == 0:\n",
    "                data.append([0,\"On Time\"])\n",
    "            else:\n",
    "                data.append([i, \"{} <= delay time < {}\".format(i * 15, (i + 1) * 15)])\n",
    "\n",
    "        df = pd.DataFrame(data=data, columns=['delay_group', 'delay_time_range(minutes)'])\n",
    "        df.to_csv('data/delay_group.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "26057385-8cbd-4cc8-8cb7-8e953a687dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_delay_group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bcdfefd3-7533-4459-80da-f42056b7925d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------------------+\n",
      "|delay_group|delay_time_range(minutes)|\n",
      "+-----------+-------------------------+\n",
      "|-1         |Early                    |\n",
      "|0          |On Time                  |\n",
      "|1          |15 <= delay time < 30    |\n",
      "|2          |30 <= delay time < 45    |\n",
      "|3          |45 <= delay time < 60    |\n",
      "|4          |60 <= delay time < 75    |\n",
      "|5          |75 <= delay time < 90    |\n",
      "|6          |90 <= delay time < 105   |\n",
      "|7          |105 <= delay time < 120  |\n",
      "|8          |120 <= delay time < 135  |\n",
      "+-----------+-------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "delay_group_df = spark.read.csv('data/delay_group.csv', header=True)\n",
    "delay_group_df.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ebf6d1-6e2d-415f-af31-60a2b77e1f4b",
   "metadata": {},
   "source": [
    "## 2. Check null values\n",
    "### 2.1 airline dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d93b761f-0564-4e12-aa28-d6a193d4d890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+\n",
      "|c_airline|      airline_name|\n",
      "+---------+------------------+\n",
      "|       AA| American Airlines|\n",
      "|       AS|   Alaska Airlines|\n",
      "|       B6|           JetBlue|\n",
      "|       DL|   Delta Air Lines|\n",
      "|       F9| Frontier Airlines|\n",
      "|       G4|     Allegiant Air|\n",
      "|       HA| Hawaiian Airlines|\n",
      "|       NK|   Spirit Airlines|\n",
      "|       UA|   United Airlines|\n",
      "|       WN|Southwest Airlines|\n",
      "+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airline_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8cba10f8-2fa2-4e9e-b5e1-b9538593adeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+\n",
      "|c_airline|airline_name|\n",
      "+---------+------------+\n",
      "+---------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airline_df.filter(col('c_airline').isNull()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7403f85-46ff-4044-9df9-480474b74327",
   "metadata": {},
   "source": [
    "There is no null value for column c_airline in airline dataframe\n",
    "### 2.2 distance_group dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ce574ae-806e-4f50-a6cb-cd891a45bb74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------------------+\n",
      "|distance_group|distance_range(miles)  |\n",
      "+--------------+-----------------------+\n",
      "|0             |0 <= distance < 250    |\n",
      "|1             |250 <= distance < 500  |\n",
      "|2             |500 <= distance < 750  |\n",
      "|3             |750 <= distance < 1000 |\n",
      "|4             |1000 <= distance < 1250|\n",
      "|5             |1250 <= distance < 1500|\n",
      "|6             |1500 <= distance < 1750|\n",
      "|7             |1750 <= distance < 2000|\n",
      "|8             |2000 <= distance < 2250|\n",
      "|9             |2250 <= distance < 2500|\n",
      "+--------------+-----------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "distance_group_df.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "17cb551b-5989-4634-b970-e68773d6a6ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------------------+\n",
      "|distance_group|distance_range(miles)|\n",
      "+--------------+---------------------+\n",
      "+--------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "distance_group_df.filter(col('distance_group').isNull()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b68dd1-7725-428e-8ee1-ed525eb331cf",
   "metadata": {},
   "source": [
    "There is no null value for column distance_group in distance_group dataframe\n",
    "### 2.3 States dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "211cc80b-57c6-4ad8-971f-34cfadd99371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------------+\n",
      "|origin_state_abr|    origin_state_nm|\n",
      "+----------------+-------------------+\n",
      "|              VI|U.S. Virgin Islands|\n",
      "|              MT|            Montana|\n",
      "|              NC|     North Carolina|\n",
      "|              MD|           Maryland|\n",
      "|              CO|           Colorado|\n",
      "|              CT|        Connecticut|\n",
      "|              IL|           Illinois|\n",
      "|              WY|            Wyoming|\n",
      "|              NJ|         New Jersey|\n",
      "|              LA|          Louisiana|\n",
      "+----------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "states_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "18d89709-170c-461f-bfed-199499249d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------------+\n",
      "|origin_state_abr|origin_state_nm|\n",
      "+----------------+---------------+\n",
      "+----------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "states_df.filter(col('origin_state_abr').isNull()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782e6c77-f996-46b8-965c-325c4960e9c1",
   "metadata": {},
   "source": [
    "There is no null value for column origin_state_abr in states dataframe\n",
    "### 2.4 port_loc dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "71c7e413-f754-4932-9932-ce4dce9d5a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------------+----------------+\n",
      "|origin|origin_city_name|origin_state_abr|\n",
      "+------+----------------+----------------+\n",
      "|   SAF|        Santa Fe|              NM|\n",
      "|   MSP|     Minneapolis|              MN|\n",
      "|   TUL|           Tulsa|              OK|\n",
      "|   DBQ|         Dubuque|              IA|\n",
      "|   LFT|       Lafayette|              LA|\n",
      "|   ROW|         Roswell|              NM|\n",
      "|   PIT|      Pittsburgh|              PA|\n",
      "|   SLN|          Salina|              KS|\n",
      "|   EAU|      Eau Claire|              WI|\n",
      "|   DCA|      Washington|              VA|\n",
      "+------+----------------+----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "port_loc_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3f3db234-fe39-478c-9a6a-23ce0a74519f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------------+----------------+\n",
      "|origin|origin_city_name|origin_state_abr|\n",
      "+------+----------------+----------------+\n",
      "+------+----------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "port_loc_df.filter(col('origin').isNull()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f66c38-4876-4fb5-a777-6fe2bb83f462",
   "metadata": {},
   "source": [
    "There is no null value for column origin in port_loc dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9cfda2-453f-47b4-b2a8-82847727f9ea",
   "metadata": {},
   "source": [
    "## 3. Create fact table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a71b3149-bf76-45cb-be4f-a3aecc2fd417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+-----+------------+-----------+--------+\n",
      "|year|quarter|month|day_of_month|day_of_week| fl_date|\n",
      "+----+-------+-----+------------+-----------+--------+\n",
      "|2020|      1|    1|           1|          3|1/1/2020|\n",
      "|2020|      1|    1|           1|          3|1/1/2020|\n",
      "|2020|      1|    1|           1|          3|1/1/2020|\n",
      "|2020|      1|    1|           1|          3|1/1/2020|\n",
      "|2020|      1|    1|           1|          3|1/1/2020|\n",
      "|2020|      1|    1|           1|          3|1/1/2020|\n",
      "|2020|      1|    1|           1|          3|1/1/2020|\n",
      "|2020|      1|    1|           1|          3|1/1/2020|\n",
      "|2020|      1|    1|           1|          3|1/1/2020|\n",
      "|2020|      1|    1|           1|          3|1/1/2020|\n",
      "+----+-------+-----+------------+-----------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select('year', 'quarter', 'month', 'day_of_month','day_of_week', 'fl_date').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ff056445-f5ca-48e3-8bbd-11a463fcfd23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+\n",
      "| fl_date|flight_date|\n",
      "+--------+-----------+\n",
      "|1/1/2020| 2020-01-01|\n",
      "|1/1/2020| 2020-01-01|\n",
      "|1/1/2020| 2020-01-01|\n",
      "|1/1/2020| 2020-01-01|\n",
      "|1/1/2020| 2020-01-01|\n",
      "|1/1/2020| 2020-01-01|\n",
      "|1/1/2020| 2020-01-01|\n",
      "|1/1/2020| 2020-01-01|\n",
      "|1/1/2020| 2020-01-01|\n",
      "|1/1/2020| 2020-01-01|\n",
      "+--------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fact_df = data.withColumn(\"flight_date\",concat_ws(\"-\",col(\"year\"),col(\"month\"),col(\"day_of_month\")).cast(\"date\"))\n",
    "# test\n",
    "fact_df.select('fl_date', 'flight_date').show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20746d7e-e22a-4087-99c6-d65df3138226",
   "metadata": {},
   "source": [
    "##### Drop column year, quarter, month, day_of_month, day_of_week, fl_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3e5281b1-78b9-4ace-b1a0-913d1949c679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- MKT_UNIQUE_CARRIER: string (nullable = true)\n",
      " |-- MKT_CARRIER_FL_NUM: string (nullable = true)\n",
      " |-- TAIL_NUM: string (nullable = true)\n",
      " |-- ORIGIN: string (nullable = true)\n",
      " |-- ORIGIN_CITY_NAME: string (nullable = true)\n",
      " |-- ORIGIN_STATE_ABR: string (nullable = true)\n",
      " |-- ORIGIN_STATE_NM: string (nullable = true)\n",
      " |-- DEST: string (nullable = true)\n",
      " |-- DEST_CITY_NAME: string (nullable = true)\n",
      " |-- DEST_STATE_ABR: string (nullable = true)\n",
      " |-- DEST_STATE_NM: string (nullable = true)\n",
      " |-- CRS_DEP_TIME: string (nullable = true)\n",
      " |-- DEP_TIME: string (nullable = true)\n",
      " |-- DEP_DELAY: string (nullable = true)\n",
      " |-- DEP_DELAY_NEW: string (nullable = true)\n",
      " |-- DEP_DEL15: string (nullable = true)\n",
      " |-- DEP_DELAY_GROUP: string (nullable = true)\n",
      " |-- DEP_TIME_BLK: string (nullable = true)\n",
      " |-- TAXI_OUT: string (nullable = true)\n",
      " |-- WHEELS_OFF: string (nullable = true)\n",
      " |-- WHEELS_ON: string (nullable = true)\n",
      " |-- TAXI_IN: string (nullable = true)\n",
      " |-- CRS_ARR_TIME: string (nullable = true)\n",
      " |-- ARR_TIME: string (nullable = true)\n",
      " |-- ARR_DELAY: string (nullable = true)\n",
      " |-- ARR_DELAY_NEW: string (nullable = true)\n",
      " |-- ARR_DEL15: string (nullable = true)\n",
      " |-- ARR_DELAY_GROUP: string (nullable = true)\n",
      " |-- ARR_TIME_BLK: string (nullable = true)\n",
      " |-- CANCELLED: string (nullable = true)\n",
      " |-- CANCELLATION_CODE: string (nullable = true)\n",
      " |-- CRS_ELAPSED_TIME: string (nullable = true)\n",
      " |-- ACTUAL_ELAPSED_TIME: string (nullable = true)\n",
      " |-- AIR_TIME: string (nullable = true)\n",
      " |-- DISTANCE: string (nullable = true)\n",
      " |-- distance_group: long (nullable = true)\n",
      " |-- CARRIER_DELAY: string (nullable = true)\n",
      " |-- WEATHER_DELAY: string (nullable = true)\n",
      " |-- NAS_DELAY: string (nullable = true)\n",
      " |-- SECURITY_DELAY: string (nullable = true)\n",
      " |-- LATE_AIRCRAFT_DELAY: string (nullable = true)\n",
      " |-- flight_date: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fact_df = fact_df.drop('year', 'quarter', 'month', 'day_of_month', 'day_of_week', 'fl_date')\n",
    "fact_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefe56b7-f5a5-456e-95f0-4defec4d9e5e",
   "metadata": {},
   "source": [
    "##### Drop columns related to origin and destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4746edd6-988f-4582-970d-4bb1d99258b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- MKT_UNIQUE_CARRIER: string (nullable = true)\n",
      " |-- MKT_CARRIER_FL_NUM: string (nullable = true)\n",
      " |-- TAIL_NUM: string (nullable = true)\n",
      " |-- ORIGIN: string (nullable = true)\n",
      " |-- DEST: string (nullable = true)\n",
      " |-- CRS_DEP_TIME: string (nullable = true)\n",
      " |-- DEP_TIME: string (nullable = true)\n",
      " |-- DEP_DELAY: string (nullable = true)\n",
      " |-- DEP_DELAY_NEW: string (nullable = true)\n",
      " |-- DEP_DEL15: string (nullable = true)\n",
      " |-- DEP_DELAY_GROUP: string (nullable = true)\n",
      " |-- DEP_TIME_BLK: string (nullable = true)\n",
      " |-- TAXI_OUT: string (nullable = true)\n",
      " |-- WHEELS_OFF: string (nullable = true)\n",
      " |-- WHEELS_ON: string (nullable = true)\n",
      " |-- TAXI_IN: string (nullable = true)\n",
      " |-- CRS_ARR_TIME: string (nullable = true)\n",
      " |-- ARR_TIME: string (nullable = true)\n",
      " |-- ARR_DELAY: string (nullable = true)\n",
      " |-- ARR_DELAY_NEW: string (nullable = true)\n",
      " |-- ARR_DEL15: string (nullable = true)\n",
      " |-- ARR_DELAY_GROUP: string (nullable = true)\n",
      " |-- ARR_TIME_BLK: string (nullable = true)\n",
      " |-- CANCELLED: string (nullable = true)\n",
      " |-- CANCELLATION_CODE: string (nullable = true)\n",
      " |-- CRS_ELAPSED_TIME: string (nullable = true)\n",
      " |-- ACTUAL_ELAPSED_TIME: string (nullable = true)\n",
      " |-- AIR_TIME: string (nullable = true)\n",
      " |-- DISTANCE: string (nullable = true)\n",
      " |-- distance_group: long (nullable = true)\n",
      " |-- CARRIER_DELAY: string (nullable = true)\n",
      " |-- WEATHER_DELAY: string (nullable = true)\n",
      " |-- NAS_DELAY: string (nullable = true)\n",
      " |-- SECURITY_DELAY: string (nullable = true)\n",
      " |-- LATE_AIRCRAFT_DELAY: string (nullable = true)\n",
      " |-- flight_date: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fact_df = fact_df.drop('origin_city_name', 'origin_state_abr', 'origin_state_nm',\\\n",
    "                       'dest_city_name', 'dest_state_abr', 'dest_state_nm')\n",
    "fact_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4d313eec-45dc-4035-afac-486dffe62536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+--------+\n",
      "|MKT_UNIQUE_CARRIER|MKT_CARRIER_FL_NUM|tail_num|\n",
      "+------------------+------------------+--------+\n",
      "|                WN|              6260|  N787SA|\n",
      "|                WN|              4789|  N7717D|\n",
      "|                WN|               665|  N969WN|\n",
      "|                WN|              1310|  N492WN|\n",
      "|                WN|              2553|  N924WN|\n",
      "|                WN|              2585|  N966WN|\n",
      "|                WN|               701|  N7828A|\n",
      "|                WN|               971|  N7710A|\n",
      "|                WN|               360|  N297WN|\n",
      "|                WN|               972|  N775SW|\n",
      "|                WN|               878|  N7853B|\n",
      "|                WN|              1786|  N933WN|\n",
      "|                WN|              4050|  N209WN|\n",
      "|                WN|              1266|  N476WN|\n",
      "|                WN|               450|  N8578Q|\n",
      "|                WN|               245|  N269WN|\n",
      "|                WN|              1166|  N8523W|\n",
      "|                WN|              1305|  N8659D|\n",
      "|                WN|              2072|  N7825A|\n",
      "|                WN|              1187|  N943WN|\n",
      "+------------------+------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_df = fact_df.select('MKT_UNIQUE_CARRIER','MKT_CARRIER_FL_NUM','tail_num').dropDuplicates()\n",
    "check_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7eec2155-650a-4f50-93f2-cade185f101c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+--------+\n",
      "|MKT_UNIQUE_CARRIER|MKT_CARRIER_FL_NUM|tail_num|\n",
      "+------------------+------------------+--------+\n",
      "|                WN|              6260|  N787SA|\n",
      "+------------------+------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_df.filter(col('tail_num')=='N787SA').filter(col('MKT_CARRIER_FL_NUM')=='6260').dropDuplicates().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "db9a4df8-749d-4f94-8936-e819e697ab62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+\n",
      "|origin|dest|\n",
      "+------+----+\n",
      "|   RNO| DEN|\n",
      "|   MCI| MKE|\n",
      "|   LAS| RNO|\n",
      "|   DEN| MCI|\n",
      "+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select('origin', 'dest').filter(col('tail_num')=='N787SA').filter(col('MKT_CARRIER_FL_NUM')=='6260').dropDuplicates().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842e0f56-c47a-4856-a210-784e170f765b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.select('fl_date', 'CRS_DEP_TIMe'                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
