{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1690f805-bbd5-41b2-bef1-37cc6a585e0f",
   "metadata": {},
   "source": [
    "# I. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49bc8971-71d8-4115-b39f-e09c92001e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.types import IntegerType\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea4581f-2039-4a3b-a683-ad6c544dff15",
   "metadata": {},
   "source": [
    "# II. Connect to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a891d67-182f-461e-b72d-c1f4f1326def",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    ".builder \\\n",
    ".appName(\"Wrangling covid19 data\") \\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d93ccaf5-4084-4e2f-b02f-2d0667557c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/jantojun2020.csv'\n",
    "data = spark.read.csv(path, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6553c3b-fbd7-4436-9626-439b44338da3",
   "metadata": {},
   "source": [
    "# III. Assess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f4fdb0e-afdf-48c1-9693-1a9109f0625b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2745847"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0840e009-7ac9-4249-a066-312aa248ff91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['YEAR',\n",
       " 'QUARTER',\n",
       " 'MONTH',\n",
       " 'DAY_OF_MONTH',\n",
       " 'DAY_OF_WEEK',\n",
       " 'FL_DATE',\n",
       " 'MKT_UNIQUE_CARRIER',\n",
       " 'MKT_CARRIER_FL_NUM',\n",
       " 'TAIL_NUM',\n",
       " 'ORIGIN',\n",
       " 'ORIGIN_CITY_NAME',\n",
       " 'ORIGIN_STATE_ABR',\n",
       " 'ORIGIN_STATE_NM',\n",
       " 'DEST',\n",
       " 'DEST_CITY_NAME',\n",
       " 'DEST_STATE_ABR',\n",
       " 'DEST_STATE_NM',\n",
       " 'CRS_DEP_TIME',\n",
       " 'DEP_TIME',\n",
       " 'DEP_DELAY',\n",
       " 'DEP_DELAY_NEW',\n",
       " 'DEP_DEL15',\n",
       " 'DEP_DELAY_GROUP',\n",
       " 'DEP_TIME_BLK',\n",
       " 'TAXI_OUT',\n",
       " 'WHEELS_OFF',\n",
       " 'WHEELS_ON',\n",
       " 'TAXI_IN',\n",
       " 'CRS_ARR_TIME',\n",
       " 'ARR_TIME',\n",
       " 'ARR_DELAY',\n",
       " 'ARR_DELAY_NEW',\n",
       " 'ARR_DEL15',\n",
       " 'ARR_DELAY_GROUP',\n",
       " 'ARR_TIME_BLK',\n",
       " 'CANCELLED',\n",
       " 'CANCELLATION_CODE',\n",
       " 'CRS_ELAPSED_TIME',\n",
       " 'ACTUAL_ELAPSED_TIME',\n",
       " 'AIR_TIME',\n",
       " 'DISTANCE',\n",
       " 'DISTANCE_GROUP',\n",
       " 'CARRIER_DELAY',\n",
       " 'WEATHER_DELAY',\n",
       " 'NAS_DELAY',\n",
       " 'SECURITY_DELAY',\n",
       " 'LATE_AIRCRAFT_DELAY']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7427faba-662c-4d35-9b8f-239cc2bc3eab",
   "metadata": {},
   "source": [
    "# IV. Wrangling data\n",
    "## 1. Split data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814a4dfc-c11c-4047-a44f-ba7729d0b85b",
   "metadata": {},
   "source": [
    "### 1.1 Create port location dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fc99101-fed5-4966-8b52-594eaef4a449",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_port_loc_df(path):\n",
    "    df = spark.read.csv(path, header=True)\n",
    "    for column in df.columns:\n",
    "        df = df.withColumnRenamed(column, column.lower())\n",
    "    port_loc_df = df.select('origin', 'origin_city_name', 'origin_state_abr').dropDuplicates()\n",
    "    port_loc_df = port_loc_df.withColumn('origin_city_name', split(port_loc_df['origin_city_name'], ',').getItem(0))\n",
    "    port_loc_df.toPandas().to_csv('data/port_loc.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9413e179-6b69-4e1b-83c8-f9d4bfd6c731",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_port_loc_df(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa963587-d9a8-4466-bffc-9d9eee69e8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------------+----------------+\n",
      "|origin|origin_city_name|origin_state_abr|\n",
      "+------+----------------+----------------+\n",
      "|   SAF|        Santa Fe|              NM|\n",
      "|   MSP|     Minneapolis|              MN|\n",
      "|   TUL|           Tulsa|              OK|\n",
      "|   DBQ|         Dubuque|              IA|\n",
      "|   LFT|       Lafayette|              LA|\n",
      "|   ROW|         Roswell|              NM|\n",
      "|   PIT|      Pittsburgh|              PA|\n",
      "|   SLN|          Salina|              KS|\n",
      "|   EAU|      Eau Claire|              WI|\n",
      "|   DCA|      Washington|              VA|\n",
      "|   PIA|          Peoria|              IL|\n",
      "|   MOT|           Minot|              ND|\n",
      "|   DAL|          Dallas|              TX|\n",
      "|   ELP|         El Paso|              TX|\n",
      "|   GSP|           Greer|              SC|\n",
      "|   TOL|          Toledo|              OH|\n",
      "|   PWM|        Portland|              ME|\n",
      "|   MSN|         Madison|              WI|\n",
      "|   MKG|        Muskegon|              MI|\n",
      "|   ORF|         Norfolk|              VA|\n",
      "+------+----------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('data/port_loc.csv', header=True)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9013921-9e45-4a11-b143-5c25a20b16ac",
   "metadata": {},
   "source": [
    "### 1.2 Create states dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4bce0066-5986-4bf6-9424-f19b5be48e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_states_df(path):\n",
    "    df = spark.read.csv(path, header=True)\n",
    "    for column in df.columns:\n",
    "        df = df.withColumnRenamed(column, column.lower())\n",
    "    state_df = df.select('origin_state_abr', 'origin_state_nm').dropDuplicates()\n",
    "    state_df.toPandas().to_csv('data/states.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "324f0393-bebf-4380-893f-74c4313392e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_states_df(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "31f1832b-f3d9-4b3d-b95d-8f435a095e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------------+\n",
      "|origin_state_abr|     origin_state_nm|\n",
      "+----------------+--------------------+\n",
      "|              VI| U.S. Virgin Islands|\n",
      "|              MT|             Montana|\n",
      "|              NC|      North Carolina|\n",
      "|              MD|            Maryland|\n",
      "|              CO|            Colorado|\n",
      "|              CT|         Connecticut|\n",
      "|              IL|            Illinois|\n",
      "|              WY|             Wyoming|\n",
      "|              NJ|          New Jersey|\n",
      "|              LA|           Louisiana|\n",
      "|              TN|           Tennessee|\n",
      "|              AR|            Arkansas|\n",
      "|              AK|              Alaska|\n",
      "|              CA|          California|\n",
      "|              NM|          New Mexico|\n",
      "|              UT|                Utah|\n",
      "|              MI|            Michigan|\n",
      "|              TT|U.S. Pacific Trus...|\n",
      "|              NY|            New York|\n",
      "|              NH|       New Hampshire|\n",
      "+----------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "state_df = spark.read.csv('data/states.csv', header=True)\n",
    "state_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d14b200-d22d-4b90-b9c4-3ab1b0bab049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1cdecc-d410-4d2a-ba05-ddc6612d7c73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
