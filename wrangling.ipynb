{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1690f805-bbd5-41b2-bef1-37cc6a585e0f",
   "metadata": {},
   "source": [
    "# I. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49bc8971-71d8-4115-b39f-e09c92001e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.types import IntegerType\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea4581f-2039-4a3b-a683-ad6c544dff15",
   "metadata": {},
   "source": [
    "# II. Connect to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a891d67-182f-461e-b72d-c1f4f1326def",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    ".builder \\\n",
    ".appName(\"Wrangling covid19 data\") \\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d93ccaf5-4084-4e2f-b02f-2d0667557c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/jantojun2020.csv'\n",
    "data = spark.read.csv(path, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6553c3b-fbd7-4436-9626-439b44338da3",
   "metadata": {},
   "source": [
    "# III. Assess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f4fdb0e-afdf-48c1-9693-1a9109f0625b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2745847"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0840e009-7ac9-4249-a066-312aa248ff91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['YEAR',\n",
       " 'QUARTER',\n",
       " 'MONTH',\n",
       " 'DAY_OF_MONTH',\n",
       " 'DAY_OF_WEEK',\n",
       " 'FL_DATE',\n",
       " 'MKT_UNIQUE_CARRIER',\n",
       " 'MKT_CARRIER_FL_NUM',\n",
       " 'TAIL_NUM',\n",
       " 'ORIGIN',\n",
       " 'ORIGIN_CITY_NAME',\n",
       " 'ORIGIN_STATE_ABR',\n",
       " 'ORIGIN_STATE_NM',\n",
       " 'DEST',\n",
       " 'DEST_CITY_NAME',\n",
       " 'DEST_STATE_ABR',\n",
       " 'DEST_STATE_NM',\n",
       " 'CRS_DEP_TIME',\n",
       " 'DEP_TIME',\n",
       " 'DEP_DELAY',\n",
       " 'DEP_DELAY_NEW',\n",
       " 'DEP_DEL15',\n",
       " 'DEP_DELAY_GROUP',\n",
       " 'DEP_TIME_BLK',\n",
       " 'TAXI_OUT',\n",
       " 'WHEELS_OFF',\n",
       " 'WHEELS_ON',\n",
       " 'TAXI_IN',\n",
       " 'CRS_ARR_TIME',\n",
       " 'ARR_TIME',\n",
       " 'ARR_DELAY',\n",
       " 'ARR_DELAY_NEW',\n",
       " 'ARR_DEL15',\n",
       " 'ARR_DELAY_GROUP',\n",
       " 'ARR_TIME_BLK',\n",
       " 'CANCELLED',\n",
       " 'CANCELLATION_CODE',\n",
       " 'CRS_ELAPSED_TIME',\n",
       " 'ACTUAL_ELAPSED_TIME',\n",
       " 'AIR_TIME',\n",
       " 'DISTANCE',\n",
       " 'DISTANCE_GROUP',\n",
       " 'CARRIER_DELAY',\n",
       " 'WEATHER_DELAY',\n",
       " 'NAS_DELAY',\n",
       " 'SECURITY_DELAY',\n",
       " 'LATE_AIRCRAFT_DELAY']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7427faba-662c-4d35-9b8f-239cc2bc3eab",
   "metadata": {},
   "source": [
    "# IV. Wrangling data\n",
    "## 1. Split data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814a4dfc-c11c-4047-a44f-ba7729d0b85b",
   "metadata": {},
   "source": [
    "### 1.1 Create port_loc dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fc99101-fed5-4966-8b52-594eaef4a449",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_port_loc_df(path):\n",
    "    df = spark.read.csv(path, header=True)\n",
    "    for column in df.columns:\n",
    "        df = df.withColumnRenamed(column, column.lower())\n",
    "    port_loc_df = df.select('origin', 'origin_city_name', 'origin_state_abr').dropDuplicates()\n",
    "    port_loc_df = port_loc_df.withColumn('origin_city_name', split(port_loc_df['origin_city_name'], ',').getItem(0))\n",
    "    port_loc_df.toPandas().to_csv('data/port_loc.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9413e179-6b69-4e1b-83c8-f9d4bfd6c731",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_port_loc_df(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa963587-d9a8-4466-bffc-9d9eee69e8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------------+----------------+\n",
      "|origin|origin_city_name|origin_state_abr|\n",
      "+------+----------------+----------------+\n",
      "|   SAF|        Santa Fe|              NM|\n",
      "|   MSP|     Minneapolis|              MN|\n",
      "|   TUL|           Tulsa|              OK|\n",
      "|   DBQ|         Dubuque|              IA|\n",
      "|   LFT|       Lafayette|              LA|\n",
      "|   ROW|         Roswell|              NM|\n",
      "|   PIT|      Pittsburgh|              PA|\n",
      "|   SLN|          Salina|              KS|\n",
      "|   EAU|      Eau Claire|              WI|\n",
      "|   DCA|      Washington|              VA|\n",
      "|   PIA|          Peoria|              IL|\n",
      "|   MOT|           Minot|              ND|\n",
      "|   DAL|          Dallas|              TX|\n",
      "|   ELP|         El Paso|              TX|\n",
      "|   GSP|           Greer|              SC|\n",
      "|   TOL|          Toledo|              OH|\n",
      "|   PWM|        Portland|              ME|\n",
      "|   MSN|         Madison|              WI|\n",
      "|   MKG|        Muskegon|              MI|\n",
      "|   ORF|         Norfolk|              VA|\n",
      "+------+----------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('data/port_loc.csv', header=True)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9013921-9e45-4a11-b143-5c25a20b16ac",
   "metadata": {},
   "source": [
    "### 1.2 Create states dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bce0066-5986-4bf6-9424-f19b5be48e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_states_df(path):\n",
    "    df = spark.read.csv(path, header=True)\n",
    "    for column in df.columns:\n",
    "        df = df.withColumnRenamed(column, column.lower())\n",
    "    state_df = df.select('origin_state_abr', 'origin_state_nm').dropDuplicates()\n",
    "    state_df.toPandas().to_csv('data/states.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "324f0393-bebf-4380-893f-74c4313392e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_states_df(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31f1832b-f3d9-4b3d-b95d-8f435a095e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------------+\n",
      "|origin_state_abr|     origin_state_nm|\n",
      "+----------------+--------------------+\n",
      "|              VI| U.S. Virgin Islands|\n",
      "|              MT|             Montana|\n",
      "|              NC|      North Carolina|\n",
      "|              MD|            Maryland|\n",
      "|              CO|            Colorado|\n",
      "|              CT|         Connecticut|\n",
      "|              IL|            Illinois|\n",
      "|              WY|             Wyoming|\n",
      "|              NJ|          New Jersey|\n",
      "|              LA|           Louisiana|\n",
      "|              TN|           Tennessee|\n",
      "|              AR|            Arkansas|\n",
      "|              AK|              Alaska|\n",
      "|              CA|          California|\n",
      "|              NM|          New Mexico|\n",
      "|              UT|                Utah|\n",
      "|              MI|            Michigan|\n",
      "|              TT|U.S. Pacific Trus...|\n",
      "|              NY|            New York|\n",
      "|              NH|       New Hampshire|\n",
      "+----------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "state_df = spark.read.csv('data/states.csv', header=True)\n",
    "state_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d14b200-d22d-4b90-b9c4-3ab1b0bab049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0ee526-a724-4011-bd49-00fb1ba45eae",
   "metadata": {},
   "source": [
    "### 1.3 Create airline dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f53c08e2-6ee4-4627-b02e-0b10f7d35658",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_airline_code(path):\n",
    "    with open(path) as f:\n",
    "        content = f.readlines()\n",
    "        content = [x.strip() for x in content]\n",
    "        airline = content[10:20]\n",
    "        splitted_airline = [c.split(\":\") for c in airline]\n",
    "        c_airline = [x[0].replace(\"'\",\"\").strip() for x in splitted_airline]\n",
    "        airline_name = [x[1].replace(\"'\",\"\").strip() for x in splitted_airline]\n",
    "        airline_df = pd.DataFrame({\"c_airline\" : c_airline, \"airline_name\": airline_name})\n",
    "        return airline_df.to_csv(\"data/airline.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15d78d1f-6a64-4e28-af6a-066537676f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/ColumnDescriptions.txt'\n",
    "create_airline_code(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e751abb6-7294-426a-9f2a-b72eda256a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+\n",
      "|c_airline|      airline_name|\n",
      "+---------+------------------+\n",
      "|       AA| American Airlines|\n",
      "|       AS|   Alaska Airlines|\n",
      "|       B6|           JetBlue|\n",
      "|       DL|   Delta Air Lines|\n",
      "|       F9| Frontier Airlines|\n",
      "|       G4|     Allegiant Air|\n",
      "|       HA| Hawaiian Airlines|\n",
      "|       NK|   Spirit Airlines|\n",
      "|       UA|   United Airlines|\n",
      "|       WN|Southwest Airlines|\n",
      "+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "spark.read.csv('data/airline.csv', header=True).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1276e3-6f68-4d25-a085-cb5bb841c457",
   "metadata": {},
   "source": [
    "### 1.4 Create distance_group dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50842d99-a77c-4ce2-8fc3-6b1d12a75569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------+\n",
      "|distance|distance_group|\n",
      "+--------+--------------+\n",
      "|     363|             2|\n",
      "|     363|             2|\n",
      "|     333|             2|\n",
      "|     333|             2|\n",
      "|     333|             2|\n",
      "|     333|             2|\n",
      "|     333|             2|\n",
      "|     390|             2|\n",
      "|     390|             2|\n",
      "|     390|             2|\n",
      "+--------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select('distance', 'distance_group').show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b93ce6c-3689-4eb7-aa1c-9dfd96115f71",
   "metadata": {},
   "source": [
    "By observing the table above, we can clearly figure out there are some wrong values in this dataframe: it should be 1 for those distances (Based on the explanation in ColumnDescriptions.txt). Therefore, we will fix it first.\n",
    "##### Fix the wrong distance_group values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b228679-71f5-4cf3-ab5f-3048330b1b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------+\n",
      "|distance|distance_group|\n",
      "+--------+--------------+\n",
      "|     363|             1|\n",
      "|     363|             1|\n",
      "|     333|             1|\n",
      "|     333|             1|\n",
      "|     333|             1|\n",
      "|     333|             1|\n",
      "|     333|             1|\n",
      "|     390|             1|\n",
      "|     390|             1|\n",
      "|     390|             1|\n",
      "+--------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use floor() to get the integer division\n",
    "data = data.withColumn('distance_group', floor(data['distance'].cast('int')/250))\n",
    "# test\n",
    "data.select('distance', 'distance_group').show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d08738-2c19-4b67-921d-10a70022d626",
   "metadata": {},
   "source": [
    "##### Create the wanted dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7eb93f0b-b395-4afb-b00a-3a2f92ee7350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|    distance_group|\n",
      "+-------+------------------+\n",
      "|  count|           2745847|\n",
      "|   mean|  2.50195659117205|\n",
      "| stddev|2.2411625220911175|\n",
      "|    min|                 0|\n",
      "|    max|                20|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select('distance_group').describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250606d9-e346-4a50-8105-02f0a4c79861",
   "metadata": {},
   "source": [
    "Because the min and the max values of the distance_group are 0 and 20, respectively,  we choose the range from 0 to 25 for this distance_group data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1609a73-aa22-4252-82b6-601b1316b2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_distance_group():\n",
    "    data = []\n",
    "    for i in range(26):\n",
    "        data.append([i, \"{} <= distance < {}\".format(i * 250, (i + 1) * 250)])\n",
    "        \n",
    "    df = pd.DataFrame(data=data, columns=['distance_group', 'distance_range(miles)'])\n",
    "    df.to_csv('data/distance_group.csv', index=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "655ec447-1ffa-440b-afb0-3b4983055269",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_distance_group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b8e894e-4e43-428b-b6c8-e15e0d3e8b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------------------+\n",
      "|distance_group|distance_range(miles)  |\n",
      "+--------------+-----------------------+\n",
      "|0             |0 <= distance < 250    |\n",
      "|1             |250 <= distance < 500  |\n",
      "|2             |500 <= distance < 750  |\n",
      "|3             |750 <= distance < 1000 |\n",
      "|4             |1000 <= distance < 1250|\n",
      "|5             |1250 <= distance < 1500|\n",
      "|6             |1500 <= distance < 1750|\n",
      "|7             |1750 <= distance < 2000|\n",
      "|8             |2000 <= distance < 2250|\n",
      "|9             |2250 <= distance < 2500|\n",
      "|10            |2500 <= distance < 2750|\n",
      "|11            |2750 <= distance < 3000|\n",
      "|12            |3000 <= distance < 3250|\n",
      "|13            |3250 <= distance < 3500|\n",
      "|14            |3500 <= distance < 3750|\n",
      "|15            |3750 <= distance < 4000|\n",
      "|16            |4000 <= distance < 4250|\n",
      "|17            |4250 <= distance < 4500|\n",
      "|18            |4500 <= distance < 4750|\n",
      "|19            |4750 <= distance < 5000|\n",
      "|20            |5000 <= distance < 5250|\n",
      "|21            |5250 <= distance < 5500|\n",
      "|22            |5500 <= distance < 5750|\n",
      "|23            |5750 <= distance < 6000|\n",
      "|24            |6000 <= distance < 6250|\n",
      "|25            |6250 <= distance < 6500|\n",
      "+--------------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "spark.read.csv('data/distance_group.csv', header=True).show(30,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f83ca6f-9608-485f-a707-5e5e0e574445",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
