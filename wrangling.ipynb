{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1690f805-bbd5-41b2-bef1-37cc6a585e0f",
   "metadata": {},
   "source": [
    "# I. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49bc8971-71d8-4115-b39f-e09c92001e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.types import IntegerType\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea4581f-2039-4a3b-a683-ad6c544dff15",
   "metadata": {},
   "source": [
    "# II. Connect to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a891d67-182f-461e-b72d-c1f4f1326def",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    ".builder \\\n",
    ".appName(\"Wrangling covid19 data\") \\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d93ccaf5-4084-4e2f-b02f-2d0667557c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/jantojun2020.csv'\n",
    "data = spark.read.csv(path, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6553c3b-fbd7-4436-9626-439b44338da3",
   "metadata": {},
   "source": [
    "# III. Assess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f4fdb0e-afdf-48c1-9693-1a9109f0625b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2745847"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "625336cb-721e-441a-95d6-4b80ae5cf036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2745847"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.na.drop(how='all')\n",
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0840e009-7ac9-4249-a066-312aa248ff91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['YEAR',\n",
       " 'QUARTER',\n",
       " 'MONTH',\n",
       " 'DAY_OF_MONTH',\n",
       " 'DAY_OF_WEEK',\n",
       " 'FL_DATE',\n",
       " 'MKT_UNIQUE_CARRIER',\n",
       " 'MKT_CARRIER_FL_NUM',\n",
       " 'TAIL_NUM',\n",
       " 'ORIGIN',\n",
       " 'ORIGIN_CITY_NAME',\n",
       " 'ORIGIN_STATE_ABR',\n",
       " 'ORIGIN_STATE_NM',\n",
       " 'DEST',\n",
       " 'DEST_CITY_NAME',\n",
       " 'DEST_STATE_ABR',\n",
       " 'DEST_STATE_NM',\n",
       " 'CRS_DEP_TIME',\n",
       " 'DEP_TIME',\n",
       " 'DEP_DELAY',\n",
       " 'DEP_DELAY_NEW',\n",
       " 'DEP_DEL15',\n",
       " 'DEP_DELAY_GROUP',\n",
       " 'DEP_TIME_BLK',\n",
       " 'TAXI_OUT',\n",
       " 'WHEELS_OFF',\n",
       " 'WHEELS_ON',\n",
       " 'TAXI_IN',\n",
       " 'CRS_ARR_TIME',\n",
       " 'ARR_TIME',\n",
       " 'ARR_DELAY',\n",
       " 'ARR_DELAY_NEW',\n",
       " 'ARR_DEL15',\n",
       " 'ARR_DELAY_GROUP',\n",
       " 'ARR_TIME_BLK',\n",
       " 'CANCELLED',\n",
       " 'CANCELLATION_CODE',\n",
       " 'CRS_ELAPSED_TIME',\n",
       " 'ACTUAL_ELAPSED_TIME',\n",
       " 'AIR_TIME',\n",
       " 'DISTANCE',\n",
       " 'DISTANCE_GROUP',\n",
       " 'CARRIER_DELAY',\n",
       " 'WEATHER_DELAY',\n",
       " 'NAS_DELAY',\n",
       " 'SECURITY_DELAY',\n",
       " 'LATE_AIRCRAFT_DELAY']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7427faba-662c-4d35-9b8f-239cc2bc3eab",
   "metadata": {},
   "source": [
    "# IV. Wrangling data\n",
    "## 1. Split data to dim tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814a4dfc-c11c-4047-a44f-ba7729d0b85b",
   "metadata": {},
   "source": [
    "### 1.1 Create port_loc dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fc99101-fed5-4966-8b52-594eaef4a449",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_port_loc_df(path):\n",
    "    df = spark.read.csv(path, header=True)\n",
    "    for column in df.columns:\n",
    "        df = df.withColumnRenamed(column, column.lower())\n",
    "    port_loc_df = df.select('origin', 'origin_city_name', 'origin_state_abr').dropDuplicates()\n",
    "    port_loc_df = port_loc_df.withColumn('origin_city_name', split(port_loc_df['origin_city_name'], ',').getItem(0))\n",
    "    port_loc_df.toPandas().to_csv('data/port_loc.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9413e179-6b69-4e1b-83c8-f9d4bfd6c731",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_port_loc_df(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa963587-d9a8-4466-bffc-9d9eee69e8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------------+----------------+\n",
      "|origin|origin_city_name|origin_state_abr|\n",
      "+------+----------------+----------------+\n",
      "|   SAF|        Santa Fe|              NM|\n",
      "|   MSP|     Minneapolis|              MN|\n",
      "|   TUL|           Tulsa|              OK|\n",
      "|   DBQ|         Dubuque|              IA|\n",
      "|   LFT|       Lafayette|              LA|\n",
      "|   ROW|         Roswell|              NM|\n",
      "|   PIT|      Pittsburgh|              PA|\n",
      "|   SLN|          Salina|              KS|\n",
      "|   EAU|      Eau Claire|              WI|\n",
      "|   DCA|      Washington|              VA|\n",
      "+------+----------------+----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "port_loc_df = spark.read.csv('data/port_loc.csv', header=True)\n",
    "port_loc_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9013921-9e45-4a11-b143-5c25a20b16ac",
   "metadata": {},
   "source": [
    "### 1.2 Create states dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4bce0066-5986-4bf6-9424-f19b5be48e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_states_df(path):\n",
    "    df = spark.read.csv(path, header=True)\n",
    "    for column in df.columns:\n",
    "        df = df.withColumnRenamed(column, column.lower())\n",
    "    state_df = df.select('origin_state_abr', 'origin_state_nm').dropDuplicates()\n",
    "    state_df.toPandas().to_csv('data/states.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "324f0393-bebf-4380-893f-74c4313392e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_states_df(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31f1832b-f3d9-4b3d-b95d-8f435a095e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------------+\n",
      "|origin_state_abr|    origin_state_nm|\n",
      "+----------------+-------------------+\n",
      "|              VI|U.S. Virgin Islands|\n",
      "|              MT|            Montana|\n",
      "|              NC|     North Carolina|\n",
      "|              MD|           Maryland|\n",
      "|              CO|           Colorado|\n",
      "|              CT|        Connecticut|\n",
      "|              IL|           Illinois|\n",
      "|              WY|            Wyoming|\n",
      "|              NJ|         New Jersey|\n",
      "|              LA|          Louisiana|\n",
      "+----------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "states_df = spark.read.csv('data/states.csv', header=True)\n",
    "states_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d14b200-d22d-4b90-b9c4-3ab1b0bab049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0ee526-a724-4011-bd49-00fb1ba45eae",
   "metadata": {},
   "source": [
    "### 1.3 Create airline dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f53c08e2-6ee4-4627-b02e-0b10f7d35658",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_airline_df(path):\n",
    "        with open(path) as f:\n",
    "            content = f.readlines()\n",
    "            content = [x.strip() for x in content]\n",
    "            airline = content[10:20]\n",
    "            splitted_airline = [c.split(\":\") for c in airline]\n",
    "            c_airline = [x[0].replace(\"'\",\"\").strip() for x in splitted_airline]\n",
    "            airline_name = [x[1].replace(\"'\",\"\").strip() for x in splitted_airline]\n",
    "            airline_df = spark.createDataFrame(zip(c_airline, airline_name), schema=['c_airline', 'airline_name'])\n",
    "            return airline_df.toPandas().to_csv(\"data/airline.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "15d78d1f-6a64-4e28-af6a-066537676f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_txt = 'data/ColumnDescriptions.txt'\n",
    "path_csv = 'data/jantojun2020.csv'\n",
    "create_airline_df(path_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e751abb6-7294-426a-9f2a-b72eda256a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+\n",
      "|c_airline|      airline_name|\n",
      "+---------+------------------+\n",
      "|       AA| American Airlines|\n",
      "|       AS|   Alaska Airlines|\n",
      "|       B6|           JetBlue|\n",
      "|       DL|   Delta Air Lines|\n",
      "|       F9| Frontier Airlines|\n",
      "|       G4|     Allegiant Air|\n",
      "|       HA| Hawaiian Airlines|\n",
      "|       NK|   Spirit Airlines|\n",
      "|       UA|   United Airlines|\n",
      "|       WN|Southwest Airlines|\n",
      "+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "airline_df = spark.read.csv('data/airline.csv', header=True)\n",
    "airline_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e08d68-a8dd-4332-b2ba-1d10006330ae",
   "metadata": {},
   "source": [
    "### 1.4 Create aircraft dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4b8268fd-026b-4268-84b2-91514355edbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_aircraft_df(path_txt,path_csv):\n",
    "        \"\"\"\n",
    "        Function: Generate and create airlines table code\n",
    "        param:\n",
    "            - path1: txt file\n",
    "            - path2: dataset file\n",
    "        output: airline.csv file stored in data folder\n",
    "        \"\"\"\n",
    "        df = spark.read.csv(path_csv, header=True).select(\"TAIL_NUM\", \"MKT_UNIQUE_CARRIER\").dropDuplicates()\n",
    "        with open(path_txt) as f:\n",
    "            content = f.readlines()\n",
    "            content = [x.strip() for x in content]\n",
    "            airline = content[10:20]\n",
    "            splitted_airline = [c.split(\":\") for c in airline]\n",
    "            c_airline = [x[0].replace(\"'\",\"\").strip() for x in splitted_airline]\n",
    "            airline_name = [x[1].replace(\"'\",\"\").strip() for x in splitted_airline]\n",
    "            airline_df = spark.createDataFrame(zip(c_airline, airline_name), schema=['c_airline', 'airline_name'])\n",
    "            aircraft_df = airline_df.join(df,airline_df.c_airline == df.MKT_UNIQUE_CARRIER,\"inner\")\n",
    "            aircraft_df = aircraft_df.select('tail_num', 'c_airline').dropDuplicates()\n",
    "            return aircraft_df.toPandas().to_csv(\"data/aircraft.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c1352c6a-46f1-4f5d-9910-067960aef490",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_aircraft_df(path_txt, path_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c8721c27-ba96-48b8-89a8-dc5217c9e03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+\n",
      "|tail_num|c_airline|\n",
      "+--------+---------+\n",
      "|  N733AR|       AA|\n",
      "|  N732AN|       AA|\n",
      "|  N736AT|       AA|\n",
      "|  N726AN|       AA|\n",
      "|  N248PS|       AA|\n",
      "|  N917FJ|       AA|\n",
      "|  N727AN|       AA|\n",
      "|  N723AN|       AA|\n",
      "|  N734AR|       AA|\n",
      "|  N729AN|       AA|\n",
      "+--------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "aircraft_df = spark.read.csv('data/aircraft.csv', header=True)\n",
    "aircraft_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1276e3-6f68-4d25-a085-cb5bb841c457",
   "metadata": {},
   "source": [
    "### 1.5 Create distance_group dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50842d99-a77c-4ce2-8fc3-6b1d12a75569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------+\n",
      "|distance|distance_group|\n",
      "+--------+--------------+\n",
      "|     363|             2|\n",
      "|     363|             2|\n",
      "|     333|             2|\n",
      "|     333|             2|\n",
      "|     333|             2|\n",
      "|     333|             2|\n",
      "|     333|             2|\n",
      "|     390|             2|\n",
      "|     390|             2|\n",
      "|     390|             2|\n",
      "+--------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select('distance', 'distance_group').show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b93ce6c-3689-4eb7-aa1c-9dfd96115f71",
   "metadata": {},
   "source": [
    "By observing the table above, we can clearly figure out there are some wrong values in this dataframe: it should be 1 for those distances (Based on the explanation in ColumnDescriptions.txt). Therefore, we will fix it first.\n",
    "##### Fix the wrong distance_group values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b228679-71f5-4cf3-ab5f-3048330b1b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------+\n",
      "|distance|distance_group|\n",
      "+--------+--------------+\n",
      "|     363|             1|\n",
      "|     363|             1|\n",
      "|     333|             1|\n",
      "|     333|             1|\n",
      "|     333|             1|\n",
      "|     333|             1|\n",
      "|     333|             1|\n",
      "|     390|             1|\n",
      "|     390|             1|\n",
      "|     390|             1|\n",
      "+--------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use floor() to get the integer division\n",
    "data = data.withColumn('distance_group', floor(data['distance'].cast('int')/250))\n",
    "# test\n",
    "data.select('distance', 'distance_group').show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d08738-2c19-4b67-921d-10a70022d626",
   "metadata": {},
   "source": [
    "##### Create the wanted dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7eb93f0b-b395-4afb-b00a-3a2f92ee7350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|    distance_group|\n",
      "+-------+------------------+\n",
      "|  count|           2745847|\n",
      "|   mean|  2.50195659117205|\n",
      "| stddev|2.2411625220911175|\n",
      "|    min|                 0|\n",
      "|    max|                20|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select('distance_group').describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250606d9-e346-4a50-8105-02f0a4c79861",
   "metadata": {},
   "source": [
    "Because the min and the max values of the distance_group are 0 and 20, respectively,  we choose the range from 0 to 22 for this distance_group data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1609a73-aa22-4252-82b6-601b1316b2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_distance_group():\n",
    "    data = []\n",
    "    for i in range(23):\n",
    "        data.append([i, \"{} <= distance < {}\".format(i * 250, (i + 1) * 250)])\n",
    "        \n",
    "    df = pd.DataFrame(data=data, columns=['distance_group', 'distance_range(miles)'])\n",
    "    df.to_csv('data/distance_group.csv', index=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "655ec447-1ffa-440b-afb0-3b4983055269",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_distance_group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b8e894e-4e43-428b-b6c8-e15e0d3e8b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------------------+\n",
      "|distance_group|distance_range(miles)  |\n",
      "+--------------+-----------------------+\n",
      "|0             |0 <= distance < 250    |\n",
      "|1             |250 <= distance < 500  |\n",
      "|2             |500 <= distance < 750  |\n",
      "|3             |750 <= distance < 1000 |\n",
      "|4             |1000 <= distance < 1250|\n",
      "|5             |1250 <= distance < 1500|\n",
      "|6             |1500 <= distance < 1750|\n",
      "|7             |1750 <= distance < 2000|\n",
      "|8             |2000 <= distance < 2250|\n",
      "|9             |2250 <= distance < 2500|\n",
      "+--------------+-----------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "distance_group_df = spark.read.csv('data/distance_group.csv', header=True)\n",
    "distance_group_df.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4daabd54-93a8-482a-abd4-bd87d8cd188e",
   "metadata": {},
   "source": [
    "### 1.6 Create cancellation dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7acfbe9c-8908-45ff-9257-de2114c3c73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cancellation_df(path):\n",
    "        \"\"\"\n",
    "        Function: Generate and create Cancelation_code table:\n",
    "        param: Path of datafile\n",
    "        input: .txt file\n",
    "        output: cancel.csv file stored in data folder\n",
    "        \"\"\"\n",
    "        import re\n",
    "        with open(path) as f:\n",
    "            content = f.readlines()\n",
    "            content = [x.strip() for x in content]\n",
    "            cancel = [re.search('\\(([^)]+)', content[49]).group(1)][0].split(\",\")\n",
    "            splitted_cancel = [c.split(\":\") for c in cancel]\n",
    "            c_cancel = [x[0].replace(\"'\",\"\").strip() for x in splitted_cancel]\n",
    "            cancel_des= [x[1].replace(\"'\",\"\").strip() for x in splitted_cancel]\n",
    "            c_cancel.append('O')\n",
    "            cancel_des.append('Non-cancel')\n",
    "            cancel_df = pd.DataFrame({\"c_cancel\" : c_cancel, \"cancel_des\": cancel_des})\n",
    "            return cancel_df.to_csv(\"data/cancellation.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "755560d0-9f9a-43be-8fae-3e6762368410",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_cancellation_df(path_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd1dc741-2195-4926-b875-68c3da6fb168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------------+\n",
      "|c_cancel|cancel_des              |\n",
      "+--------+------------------------+\n",
      "|A       |Carrier                 |\n",
      "|B       |Weather                 |\n",
      "|C       |National Aviation System|\n",
      "|D       |Security                |\n",
      "|O       |Non-cancel              |\n",
      "+--------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "cancel_df = spark.read.csv('data/cancellation.csv', header=True)\n",
    "cancel_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6c0c2c-f033-48e0-8886-7929f26ad3f5",
   "metadata": {},
   "source": [
    "### 1.7 Create delay_group dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "01df0aa1-ec39-4cfd-a6b5-aa10d419f5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_delay_group():\n",
    "        \"\"\"\n",
    "        function\n",
    "        \"\"\"\n",
    "        data = []\n",
    "        for i in range(-1,188):\n",
    "            if i == -1:\n",
    "                data.append([-1,\"Early\"])\n",
    "            elif i == 0:\n",
    "                data.append([0,\"On Time\"])\n",
    "            else:\n",
    "                data.append([i, \"{} <= delay time < {}\".format(i * 15, (i + 1) * 15)])\n",
    "\n",
    "        df = pd.DataFrame(data=data, columns=['delay_group', 'delay_time_range(minutes)'])\n",
    "        df.to_csv('data/delay_group.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "26057385-8cbd-4cc8-8cb7-8e953a687dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_delay_group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bcdfefd3-7533-4459-80da-f42056b7925d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------------------+\n",
      "|delay_group|delay_time_range(minutes)|\n",
      "+-----------+-------------------------+\n",
      "|-1         |Early                    |\n",
      "|0          |On Time                  |\n",
      "|1          |15 <= delay time < 30    |\n",
      "|2          |30 <= delay time < 45    |\n",
      "|3          |45 <= delay time < 60    |\n",
      "|4          |60 <= delay time < 75    |\n",
      "|5          |75 <= delay time < 90    |\n",
      "|6          |90 <= delay time < 105   |\n",
      "|7          |105 <= delay time < 120  |\n",
      "|8          |120 <= delay time < 135  |\n",
      "+-----------+-------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "delay_group_df = spark.read.csv('data/delay_group.csv', header=True)\n",
    "delay_group_df.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ebf6d1-6e2d-415f-af31-60a2b77e1f4b",
   "metadata": {},
   "source": [
    "## 2. Check null values\n",
    "### 2.1 airline dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d93b761f-0564-4e12-aa28-d6a193d4d890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------------+------------------+--------+\n",
      "|c_airline|   airline_name|MKT_CARRIER_FL_NUM|TAIL_NUM|\n",
      "+---------+---------------+------------------+--------+\n",
      "|       NK|Spirit Airlines|              1009|  N624NK|\n",
      "|       NK|Spirit Airlines|               103|  N654NK|\n",
      "|       NK|Spirit Airlines|              1069|  N913NK|\n",
      "|       NK|Spirit Airlines|               109|  N507NK|\n",
      "|       NK|Spirit Airlines|              1247|  N648NK|\n",
      "|       NK|Spirit Airlines|              1360|  N629NK|\n",
      "|       NK|Spirit Airlines|              1400|  N602NK|\n",
      "|       NK|Spirit Airlines|              1440|  N915NK|\n",
      "|       NK|Spirit Airlines|              1520|  N672NK|\n",
      "|       NK|Spirit Airlines|              1782|  N627NK|\n",
      "+---------+---------------+------------------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airline_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8cba10f8-2fa2-4e9e-b5e1-b9538593adeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+------------------+--------+\n",
      "|c_airline|airline_name|MKT_CARRIER_FL_NUM|TAIL_NUM|\n",
      "+---------+------------+------------------+--------+\n",
      "+---------+------------+------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airline_df.filter(col('c_airline').isNull()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7403f85-46ff-4044-9df9-480474b74327",
   "metadata": {},
   "source": [
    "There is no null value for column c_airline in airline dataframe\n",
    "### 2.2 distance_group dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7ce574ae-806e-4f50-a6cb-cd891a45bb74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------------------+\n",
      "|distance_group|distance_range(miles)  |\n",
      "+--------------+-----------------------+\n",
      "|0             |0 <= distance < 250    |\n",
      "|1             |250 <= distance < 500  |\n",
      "|2             |500 <= distance < 750  |\n",
      "|3             |750 <= distance < 1000 |\n",
      "|4             |1000 <= distance < 1250|\n",
      "|5             |1250 <= distance < 1500|\n",
      "|6             |1500 <= distance < 1750|\n",
      "|7             |1750 <= distance < 2000|\n",
      "|8             |2000 <= distance < 2250|\n",
      "|9             |2250 <= distance < 2500|\n",
      "+--------------+-----------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "distance_group_df.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "17cb551b-5989-4634-b970-e68773d6a6ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------------------+\n",
      "|distance_group|distance_range(miles)|\n",
      "+--------------+---------------------+\n",
      "+--------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "distance_group_df.filter(col('distance_group').isNull()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b68dd1-7725-428e-8ee1-ed525eb331cf",
   "metadata": {},
   "source": [
    "There is no null value for column distance_group in distance_group dataframe\n",
    "### 2.3 States dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "211cc80b-57c6-4ad8-971f-34cfadd99371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------------+\n",
      "|origin_state_abr|    origin_state_nm|\n",
      "+----------------+-------------------+\n",
      "|              VI|U.S. Virgin Islands|\n",
      "|              MT|            Montana|\n",
      "|              NC|     North Carolina|\n",
      "|              MD|           Maryland|\n",
      "|              CO|           Colorado|\n",
      "|              CT|        Connecticut|\n",
      "|              IL|           Illinois|\n",
      "|              WY|            Wyoming|\n",
      "|              NJ|         New Jersey|\n",
      "|              LA|          Louisiana|\n",
      "+----------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "states_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "18d89709-170c-461f-bfed-199499249d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------------+\n",
      "|origin_state_abr|origin_state_nm|\n",
      "+----------------+---------------+\n",
      "+----------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "states_df.filter(col('origin_state_abr').isNull()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782e6c77-f996-46b8-965c-325c4960e9c1",
   "metadata": {},
   "source": [
    "There is no null value for column origin_state_abr in states dataframe\n",
    "### 2.4 port_loc dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "71c7e413-f754-4932-9932-ce4dce9d5a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------------+----------------+\n",
      "|origin|origin_city_name|origin_state_abr|\n",
      "+------+----------------+----------------+\n",
      "|   SAF|        Santa Fe|              NM|\n",
      "|   MSP|     Minneapolis|              MN|\n",
      "|   TUL|           Tulsa|              OK|\n",
      "|   DBQ|         Dubuque|              IA|\n",
      "|   LFT|       Lafayette|              LA|\n",
      "|   ROW|         Roswell|              NM|\n",
      "|   PIT|      Pittsburgh|              PA|\n",
      "|   SLN|          Salina|              KS|\n",
      "|   EAU|      Eau Claire|              WI|\n",
      "|   DCA|      Washington|              VA|\n",
      "+------+----------------+----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "port_loc_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3f3db234-fe39-478c-9a6a-23ce0a74519f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------------+----------------+\n",
      "|origin|origin_city_name|origin_state_abr|\n",
      "+------+----------------+----------------+\n",
      "+------+----------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "port_loc_df.filter(col('origin').isNull()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f66c38-4876-4fb5-a777-6fe2bb83f462",
   "metadata": {},
   "source": [
    "There is no null value for column origin in port_loc dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9cfda2-453f-47b4-b2a8-82847727f9ea",
   "metadata": {},
   "source": [
    "## 3. Create fact table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a71b3149-bf76-45cb-be4f-a3aecc2fd417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+-----+------------+-----------+--------+\n",
      "|year|quarter|month|day_of_month|day_of_week| fl_date|\n",
      "+----+-------+-----+------------+-----------+--------+\n",
      "|2020|      1|    1|           1|          3|1/1/2020|\n",
      "|2020|      1|    1|           1|          3|1/1/2020|\n",
      "|2020|      1|    1|           1|          3|1/1/2020|\n",
      "|2020|      1|    1|           1|          3|1/1/2020|\n",
      "|2020|      1|    1|           1|          3|1/1/2020|\n",
      "|2020|      1|    1|           1|          3|1/1/2020|\n",
      "|2020|      1|    1|           1|          3|1/1/2020|\n",
      "|2020|      1|    1|           1|          3|1/1/2020|\n",
      "|2020|      1|    1|           1|          3|1/1/2020|\n",
      "|2020|      1|    1|           1|          3|1/1/2020|\n",
      "+----+-------+-----+------------+-----------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select('year', 'quarter', 'month', 'day_of_month','day_of_week', 'fl_date').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ff056445-f5ca-48e3-8bbd-11a463fcfd23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+\n",
      "| fl_date|flight_date|\n",
      "+--------+-----------+\n",
      "|1/1/2020| 2020-01-01|\n",
      "|1/1/2020| 2020-01-01|\n",
      "|1/1/2020| 2020-01-01|\n",
      "|1/1/2020| 2020-01-01|\n",
      "|1/1/2020| 2020-01-01|\n",
      "|1/1/2020| 2020-01-01|\n",
      "|1/1/2020| 2020-01-01|\n",
      "|1/1/2020| 2020-01-01|\n",
      "|1/1/2020| 2020-01-01|\n",
      "|1/1/2020| 2020-01-01|\n",
      "+--------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fact_df = data.withColumn(\"flight_date\",concat_ws(\"-\",col(\"year\"),col(\"month\"),col(\"day_of_month\")).cast(\"date\"))\n",
    "# test\n",
    "fact_df.select('fl_date', 'flight_date').show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20746d7e-e22a-4087-99c6-d65df3138226",
   "metadata": {},
   "source": [
    "#### Drop column year, quarter, month, day_of_month, day_of_week, fl_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3e5281b1-78b9-4ace-b1a0-913d1949c679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- MKT_UNIQUE_CARRIER: string (nullable = true)\n",
      " |-- MKT_CARRIER_FL_NUM: string (nullable = true)\n",
      " |-- TAIL_NUM: string (nullable = true)\n",
      " |-- ORIGIN: string (nullable = true)\n",
      " |-- ORIGIN_CITY_NAME: string (nullable = true)\n",
      " |-- ORIGIN_STATE_ABR: string (nullable = true)\n",
      " |-- ORIGIN_STATE_NM: string (nullable = true)\n",
      " |-- DEST: string (nullable = true)\n",
      " |-- DEST_CITY_NAME: string (nullable = true)\n",
      " |-- DEST_STATE_ABR: string (nullable = true)\n",
      " |-- DEST_STATE_NM: string (nullable = true)\n",
      " |-- CRS_DEP_TIME: string (nullable = true)\n",
      " |-- DEP_TIME: string (nullable = true)\n",
      " |-- DEP_DELAY: string (nullable = true)\n",
      " |-- DEP_DELAY_NEW: string (nullable = true)\n",
      " |-- DEP_DEL15: string (nullable = true)\n",
      " |-- DEP_DELAY_GROUP: string (nullable = true)\n",
      " |-- DEP_TIME_BLK: string (nullable = true)\n",
      " |-- TAXI_OUT: string (nullable = true)\n",
      " |-- WHEELS_OFF: string (nullable = true)\n",
      " |-- WHEELS_ON: string (nullable = true)\n",
      " |-- TAXI_IN: string (nullable = true)\n",
      " |-- CRS_ARR_TIME: string (nullable = true)\n",
      " |-- ARR_TIME: string (nullable = true)\n",
      " |-- ARR_DELAY: string (nullable = true)\n",
      " |-- ARR_DELAY_NEW: string (nullable = true)\n",
      " |-- ARR_DEL15: string (nullable = true)\n",
      " |-- ARR_DELAY_GROUP: string (nullable = true)\n",
      " |-- ARR_TIME_BLK: string (nullable = true)\n",
      " |-- CANCELLED: string (nullable = true)\n",
      " |-- CANCELLATION_CODE: string (nullable = true)\n",
      " |-- CRS_ELAPSED_TIME: string (nullable = true)\n",
      " |-- ACTUAL_ELAPSED_TIME: string (nullable = true)\n",
      " |-- AIR_TIME: string (nullable = true)\n",
      " |-- DISTANCE: string (nullable = true)\n",
      " |-- distance_group: long (nullable = true)\n",
      " |-- CARRIER_DELAY: string (nullable = true)\n",
      " |-- WEATHER_DELAY: string (nullable = true)\n",
      " |-- NAS_DELAY: string (nullable = true)\n",
      " |-- SECURITY_DELAY: string (nullable = true)\n",
      " |-- LATE_AIRCRAFT_DELAY: string (nullable = true)\n",
      " |-- flight_date: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fact_df = fact_df.drop('year', 'quarter', 'month', 'day_of_month', 'day_of_week', 'fl_date')\n",
    "fact_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefe56b7-f5a5-456e-95f0-4defec4d9e5e",
   "metadata": {},
   "source": [
    "#### Drop columns related to origin and destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4746edd6-988f-4582-970d-4bb1d99258b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- MKT_UNIQUE_CARRIER: string (nullable = true)\n",
      " |-- MKT_CARRIER_FL_NUM: string (nullable = true)\n",
      " |-- TAIL_NUM: string (nullable = true)\n",
      " |-- ORIGIN: string (nullable = true)\n",
      " |-- DEST: string (nullable = true)\n",
      " |-- CRS_DEP_TIME: string (nullable = true)\n",
      " |-- DEP_TIME: string (nullable = true)\n",
      " |-- DEP_DELAY: string (nullable = true)\n",
      " |-- DEP_DELAY_NEW: string (nullable = true)\n",
      " |-- DEP_DEL15: string (nullable = true)\n",
      " |-- DEP_DELAY_GROUP: string (nullable = true)\n",
      " |-- DEP_TIME_BLK: string (nullable = true)\n",
      " |-- TAXI_OUT: string (nullable = true)\n",
      " |-- WHEELS_OFF: string (nullable = true)\n",
      " |-- WHEELS_ON: string (nullable = true)\n",
      " |-- TAXI_IN: string (nullable = true)\n",
      " |-- CRS_ARR_TIME: string (nullable = true)\n",
      " |-- ARR_TIME: string (nullable = true)\n",
      " |-- ARR_DELAY: string (nullable = true)\n",
      " |-- ARR_DELAY_NEW: string (nullable = true)\n",
      " |-- ARR_DEL15: string (nullable = true)\n",
      " |-- ARR_DELAY_GROUP: string (nullable = true)\n",
      " |-- ARR_TIME_BLK: string (nullable = true)\n",
      " |-- CANCELLED: string (nullable = true)\n",
      " |-- CANCELLATION_CODE: string (nullable = true)\n",
      " |-- CRS_ELAPSED_TIME: string (nullable = true)\n",
      " |-- ACTUAL_ELAPSED_TIME: string (nullable = true)\n",
      " |-- AIR_TIME: string (nullable = true)\n",
      " |-- DISTANCE: string (nullable = true)\n",
      " |-- distance_group: long (nullable = true)\n",
      " |-- CARRIER_DELAY: string (nullable = true)\n",
      " |-- WEATHER_DELAY: string (nullable = true)\n",
      " |-- NAS_DELAY: string (nullable = true)\n",
      " |-- SECURITY_DELAY: string (nullable = true)\n",
      " |-- LATE_AIRCRAFT_DELAY: string (nullable = true)\n",
      " |-- flight_date: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fact_df = fact_df.drop('origin_city_name', 'origin_state_abr', 'origin_state_nm',\\\n",
    "                       'dest_city_name', 'dest_state_abr', 'dest_state_nm')\n",
    "fact_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33ba456-cb2f-42d1-8038-1f76c2a65ffc",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Drop column cancelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d52154bc-360a-4bba-9ff2-dfe12f75a2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_df = fact_df.drop('cancelled')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175ce2be-1c17-4ff0-8ab5-c771ee01eb33",
   "metadata": {},
   "source": [
    "Then we substitute all null values of column cancellation code with 'O' (means ' Non-cancel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ffc79473-f430-489e-b3e3-776cfcd6af0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|cancellation_code|\n",
      "+-----------------+\n",
      "|             null|\n",
      "|                B|\n",
      "|                D|\n",
      "|                C|\n",
      "|                A|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fact_df.select('cancellation_code').dropDuplicates().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fcc34f1f-5d4b-495f-a148-0ee2566e1fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|cancellation_code|\n",
      "+-----------------+\n",
      "|                B|\n",
      "|                O|\n",
      "|                D|\n",
      "|                C|\n",
      "|                A|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fact_df = fact_df.na.fill(value='O',subset=[\"cancellation_code\"])\n",
    "# test\n",
    "fact_df.select('cancellation_code').dropDuplicates().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b7bd75-93cd-4edb-9cdb-974e5bedfa52",
   "metadata": {},
   "source": [
    "#### Modify the departure time and the arrival time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cc722150-33a8-42dd-8411-8dc85d6418cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+------------+--------+\n",
      "|crs_arr_time|arr_time|crs_dep_time|dep_time|\n",
      "+------------+--------+------------+--------+\n",
      "|        1945|  2053.0|        1810|  1851.0|\n",
      "|        1320|  1318.0|        1150|  1146.0|\n",
      "|        2130|  2124.0|        2020|  2016.0|\n",
      "|        1455|  1505.0|        1340|  1350.0|\n",
      "|        1035|  1023.0|         915|   916.0|\n",
      "|         715|   722.0|         600|   602.0|\n",
      "|        1740|  1736.0|        1620|  1624.0|\n",
      "|        1630|  1717.0|        1505|  1604.0|\n",
      "|        1355|  1405.0|        1230|  1225.0|\n",
      "|         900|   904.0|         740|   740.0|\n",
      "+------------+--------+------------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fact_df.select('crs_arr_time', 'arr_time', 'crs_dep_time', 'dep_time').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5af263e1-d3df-42ea-8aca-aab484baa91a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "287334"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fact_df.filter(col('arr_delay_group').isNull() | col('dep_delay_group').isNull()).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f551bb0-b558-4229-9b02-fc8b9794fe4f",
   "metadata": {},
   "source": [
    "There are null values in the departure delay group and the arrival delay group. Because we do not have any appropriate substituted values and because we would like to consider the delay and cancelation, it is non-sense to keep those null values, so we will drop all those rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "043aee77-e0ad-4ea2-98e7-b72a3a996c8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fact_df = fact_df.dropna(subset=['arr_delay_group', 'dep_delay_group'])\n",
    "# test\n",
    "fact_df.filter(col('arr_delay_group').isNull() | col('dep_delay_group').isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ff85a571-2e9e-44b6-817a-379b5643fdb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+------------+--------+\n",
      "|crs_arr_time|arr_time|crs_dep_time|dep_time|\n",
      "+------------+--------+------------+--------+\n",
      "|        1945|    2053|        1810|    1851|\n",
      "|        1320|    1318|        1150|    1146|\n",
      "|        2130|    2124|        2020|    2016|\n",
      "|        1455|    1505|        1340|    1350|\n",
      "|        1035|    1023|        0915|    0916|\n",
      "|        0715|    0722|        0600|    0602|\n",
      "|        1740|    1736|        1620|    1624|\n",
      "|        1630|    1717|        1505|    1604|\n",
      "|        1355|    1405|        1230|    1225|\n",
      "|        0900|    0904|        0740|    0740|\n",
      "+------------+--------+------------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use lpad() to add '0' leading\n",
    "fact_df = (fact_df.withColumn('crs_arr_time', lpad(col('crs_arr_time'), 4, '0'))\n",
    "                  .withColumn('arr_time', lpad(col('arr_time').cast('int'), 4, '0'))\n",
    "                  .withColumn('crs_dep_time', lpad(col('crs_dep_time'), 4, '0'))\n",
    "                  .withColumn('dep_time', lpad(col('dep_time').cast('int'), 4, '0')))\n",
    "# test\n",
    "fact_df.select('crs_arr_time', 'arr_time', 'crs_dep_time', 'dep_time').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4b188f25-f1ac-4ba5-8bfd-07dee341b86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+------------+--------+\n",
      "|crs_arr_time|arr_time|crs_dep_time|dep_time|\n",
      "+------------+--------+------------+--------+\n",
      "|       19:45|   20:53|       18:10|   18:51|\n",
      "|       13:20|   13:18|       11:50|   11:46|\n",
      "|       21:30|   21:24|       20:20|   20:16|\n",
      "|       14:55|   15:05|       13:40|   13:50|\n",
      "|       10:35|   10:23|       09:15|   09:16|\n",
      "|       07:15|   07:22|       06:00|   06:02|\n",
      "|       17:40|   17:36|       16:20|   16:24|\n",
      "|       16:30|   17:17|       15:05|   16:04|\n",
      "|       13:55|   14:05|       12:30|   12:25|\n",
      "|       09:00|   09:04|       07:40|   07:40|\n",
      "+------------+--------+------------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# convert time from str to timestamp\n",
    "fact_df = (fact_df.withColumn('crs_arr_time', date_format(to_timestamp(col('crs_arr_time'), 'Hmm'),'HH:mm'))\n",
    "                  .withColumn('arr_time', date_format(to_timestamp(col('arr_time'), 'Hmm'),'HH:mm'))\n",
    "                  .withColumn('crs_dep_time', date_format(to_timestamp(col('crs_dep_time'), 'Hmm'),'HH:mm'))\n",
    "                  .withColumn('dep_time', date_format(to_timestamp(col('dep_time'), 'Hmm'),'HH:mm')))\n",
    "# test\n",
    "fact_df.select('crs_arr_time', 'arr_time', 'crs_dep_time', 'dep_time').show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1082c5d8-df3e-4feb-a804-9adee1d16cec",
   "metadata": {},
   "source": [
    "Then, when we created a delay_group dataframe, we realized that there are some wrong numbers in the column dep_delay_group. Thus, we will fix them right now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "75480494-a64e-4a39-bccf-4da568193a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the dep_delay_group and arr_delay_group\n",
    "fact_df = (fact_df.withColumn('arr_delay_group', floor(col('arr_delay').cast('int')/15))\n",
    "                  .withColumn('dep_delay_group', floor(col('arr_delay').cast('int')/15)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3045e2e3-839c-4a69-9189-c0fa4151c8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unneeded columns\n",
    "fact_df = fact_df.drop('arr_delay', 'arr_delay_new', 'arr_del15', 'arr_time_blk', \\\n",
    "             'dep_delay', 'dep_delay_new', 'dep_del15', 'dep_time_blk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6636ad66-ae32-4fd7-85de-2520db1478b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MKT_UNIQUE_CARRIER',\n",
       " 'MKT_CARRIER_FL_NUM',\n",
       " 'TAIL_NUM',\n",
       " 'ORIGIN',\n",
       " 'DEST',\n",
       " 'crs_dep_time',\n",
       " 'dep_time',\n",
       " 'dep_delay_group',\n",
       " 'TAXI_OUT',\n",
       " 'WHEELS_OFF',\n",
       " 'WHEELS_ON',\n",
       " 'TAXI_IN',\n",
       " 'crs_arr_time',\n",
       " 'arr_time',\n",
       " 'arr_delay_group',\n",
       " 'CANCELLATION_CODE',\n",
       " 'CRS_ELAPSED_TIME',\n",
       " 'ACTUAL_ELAPSED_TIME',\n",
       " 'AIR_TIME',\n",
       " 'DISTANCE',\n",
       " 'distance_group',\n",
       " 'CARRIER_DELAY',\n",
       " 'WEATHER_DELAY',\n",
       " 'NAS_DELAY',\n",
       " 'SECURITY_DELAY',\n",
       " 'LATE_AIRCRAFT_DELAY',\n",
       " 'flight_date']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fact_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e552da50-8581-4274-8ce9-c702481e2927",
   "metadata": {},
   "source": [
    "#### Modify distance related columns\n",
    "When we created a distance_group dataframe, we realized that there are some wrong numbers in the column distance_group. Thus, we will fix them right now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "69579e07-21c3-43a2-871d-77ee2a03cf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_df = fact_df.withColumn('distance_group', floor(col('distance').cast('int')/250))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8c3cce23-f318-41c0-b4ff-7554331a2213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop column distance\n",
    "fact_df = fact_df.drop('distance')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b11f91-5a19-448f-8b4c-b5a38539f31e",
   "metadata": {},
   "source": [
    "#### Drop unneeded columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d09dab3b-ec10-4cef-9885-8e5bea7c66d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_df = fact_df.drop('taxi_out', 'wheels_off', 'wheels_on', 'taxi_in', 'crs_elapsed_time', 'actual_elapsed_time', 'air_time',\\\n",
    "             'carrier_delay', 'weather_delay', 'nas_delay', 'security_delay', 'late_aircraft_delay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2852a5f2-596e-40b5-b827-1d50f17215b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- MKT_UNIQUE_CARRIER: string (nullable = true)\n",
      " |-- MKT_CARRIER_FL_NUM: string (nullable = true)\n",
      " |-- TAIL_NUM: string (nullable = true)\n",
      " |-- ORIGIN: string (nullable = true)\n",
      " |-- DEST: string (nullable = true)\n",
      " |-- crs_dep_time: string (nullable = true)\n",
      " |-- dep_time: string (nullable = true)\n",
      " |-- dep_delay_group: long (nullable = true)\n",
      " |-- crs_arr_time: string (nullable = true)\n",
      " |-- arr_time: string (nullable = true)\n",
      " |-- arr_delay_group: long (nullable = true)\n",
      " |-- CANCELLATION_CODE: string (nullable = false)\n",
      " |-- distance_group: long (nullable = true)\n",
      " |-- flight_date: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "fact_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c6ce6da4-35bc-4fad-9284-ceff26a1681b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2458513"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fact_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8c3e8c76-c75c-499a-b56d-b9c0d250f654",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_df.toPandas().to_csv('data/fact.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "666d61f1-ab7e-4f66-b911-a894b2aaad9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+--------+------+----+------------+--------+---------------+------------+--------+---------------+-----------------+--------------+-----------+\n",
      "|MKT_UNIQUE_CARRIER|MKT_CARRIER_FL_NUM|TAIL_NUM|ORIGIN|DEST|crs_dep_time|dep_time|dep_delay_group|crs_arr_time|arr_time|arr_delay_group|CANCELLATION_CODE|distance_group|flight_date|\n",
      "+------------------+------------------+--------+------+----+------------+--------+---------------+------------+--------+---------------+-----------------+--------------+-----------+\n",
      "|                WN|              5888|  N951WN|   ONT| SFO|       18:10|   18:51|              4|       19:45|   20:53|              4|                O|             1| 2020-01-01|\n",
      "|                WN|              6276|  N467WN|   ONT| SFO|       11:50|   11:46|             -1|       13:20|   13:18|             -1|                O|             1| 2020-01-01|\n",
      "|                WN|              4598|  N7885A|   ONT| SJC|       20:20|   20:16|             -1|       21:30|   21:24|             -1|                O|             1| 2020-01-01|\n",
      "|                WN|              4761|  N551WN|   ONT| SJC|       13:40|   13:50|              0|       14:55|   15:05|              0|                O|             1| 2020-01-01|\n",
      "|                WN|              5162|  N968WN|   ONT| SJC|       09:15|   09:16|             -1|       10:35|   10:23|             -1|                O|             1| 2020-01-01|\n",
      "|                WN|              5684|  N7856A|   ONT| SJC|       06:00|   06:02|              0|       07:15|   07:22|              0|                O|             1| 2020-01-01|\n",
      "|                WN|              6152|  N7735A|   ONT| SJC|       16:20|   16:24|             -1|       17:40|   17:36|             -1|                O|             1| 2020-01-01|\n",
      "|                WN|              1679|  N405WN|   ONT| SMF|       15:05|   16:04|              3|       16:30|   17:17|              3|                O|             1| 2020-01-01|\n",
      "|                WN|              3479|  N489WN|   ONT| SMF|       12:30|   12:25|              0|       13:55|   14:05|              0|                O|             1| 2020-01-01|\n",
      "|                WN|              4069|  N7708E|   ONT| SMF|       07:40|   07:40|              0|       09:00|   09:04|              0|                O|             1| 2020-01-01|\n",
      "|                WN|              4905|  N426WN|   ONT| SMF|       10:25|   10:22|             -1|       11:55|   11:47|             -1|                O|             1| 2020-01-01|\n",
      "|                WN|              4918|  N455WN|   ONT| SMF|       20:40|   20:35|              0|       21:55|   21:57|              0|                O|             1| 2020-01-01|\n",
      "|                WN|              5144|  N8314L|   ONT| SMF|       22:50|   22:46|              0|       00:05|   00:06|              0|                O|             1| 2020-01-01|\n",
      "|                WN|              5722|  N7820L|   ONT| SMF|       18:10|   18:15|             -1|       19:30|   19:29|             -1|                O|             1| 2020-01-01|\n",
      "|                WN|              3719|  N941WN|   ORF| BWI|       11:30|   12:30|              2|       12:35|   13:17|              2|                O|             0| 2020-01-01|\n",
      "|                WN|              4863|  N496WN|   ORF| BWI|       06:30|   06:29|             -1|       07:30|   07:15|             -1|                O|             0| 2020-01-01|\n",
      "|                WN|              4924|  N7732A|   ORF| BWI|       20:20|   20:13|             -2|       21:20|   21:02|             -2|                O|             0| 2020-01-01|\n",
      "|                WN|              5321|  N7863A|   ORF| BWI|       17:45|   17:46|             -2|       18:55|   18:38|             -2|                O|             0| 2020-01-01|\n",
      "|                WN|              4618|  N928WN|   ORF| MCO|       10:50|   10:45|             -2|       12:55|   12:37|             -2|                O|             2| 2020-01-01|\n",
      "|                WN|              5992|  N410WN|   ORF| MDW|       16:50|   16:49|             -2|       18:10|   17:54|             -2|                O|             2| 2020-01-01|\n",
      "+------------------+------------------+--------+------+----+------------+--------+---------------+------------+--------+---------------+-----------------+--------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test = spark.read.csv('data/fact.csv', header=True)\n",
    "test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2817d2b8-11c2-4237-b67a-a335dc6e0c36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
